>[MIT6.824心得](https://hanqi-blog.com/posts/mit6.824/)
>此外，分布式系统的 bug 还有一个特征就是信息量大。分布式系统典型特性是多个程序并发地更新同一个状态。所以当一个状态更新出问题时，它的上下文信息量非常之大，以至于需要额外写工具去解析日志，并且详略得当地阅读日志，否则就会”淹没在几百个线程更新一个结构体的十几个 field 之中“。于是结合之前工作总结出的 debug 方法，结合分布式系统的特性，我改进出了一套 debug 方法助我平安落地：
>1. 对日志建立一种协议（Protocol）。有没有协议的概念几乎是程序员入门的分水岭。”你要自动化“，这句话人人都会说，但是落实到手上就只有少数人能做到。建立自动化的基础就是建立具有一致性的协议。比如 Django 可以用很少的程序自动生成一套 CRUD 接口，就是因为这个接口是基于 RESTful 的。如果不同接口的 delete 方法分别通过 HTTP body 或者 URL 去传参，那么自动化生成无从谈起。回到 6.824，我为日志设计了一套格式，包括从零计数的时间点（时间线在分布式系统里面是非常重要的 debug 信息）、主题、日志的主体以及其从属的 Replica Group，后面是发生的事件和需要关注的状态值。具体是这样的： `000025 EXCUTE G100 S0 execute cmd: xWSuqTRyhVMWYGJFaNtQMAcF`当具备了这个协议之后，就可以利用脚本做一些自动化。比如做 lab4 时不同 Replica Group 的不同 Server 日志混在一起非常难以阅读，我就可以轻松写出一个脚本来把不同 Server 的日志解析到不同的文件中。未来需要的话还可以为 VSCode 写一个插件对日志进行高亮。
>2. 对同一个事件建立一个全局唯一的追踪 ID。面对浩如烟海的日志，最重要的是把关心的日志找出来，其中最好的方法就是生成全局性 ID 串起一个事件。比如 Raft 选举时我就会把 RPC 发送方和接收方请求、响应、更新前后的状态值都用同一个 ID 关联。这样整个事件哪一步出了错一目了然。
>3. 千里之堤毁于蚁穴，利用单元测试缩短数据流。debug 最大的敌人就是巨大的上下文。一个很小的 bug 放入分布式系统的背景中，都会演变成一个复杂的毛线团。如果针对复杂状态的程序先用单元测试把 bug 早早暴露出来，那么后期做集成测试时就能节省大量的时间。比如我在 lab4 设计 join 和 leave 的算法，以及 Raft 设计日志的数据结构时都写了尽可能多的单元测试 case，为我后来过集成测试节省了大量时间。
>4. 抽象封装。把关联性很强的状态、程序抽象成函数或者方法是管理软件复杂度的核心。在实现 Raft 日志数据结构时我很自然地封装出了一个数据结构，把各种操作写成了接口，而不是直接读写内部的数据结构，这为我后续的 lab 节省了大量时间。最初的内部实现是很直接的数组，到了实现快照压缩日志时，发现 Go 的数组无法满足我的需求，需要在内部封装一些状态值来标记是否做了截断。因为做了封装，所以外部的调用方完全不需要改动，只是把内部改好，保证过了之前写好的单元测试，就得到了安全性的保证。
>5. Let it crash。在容易出错的地方加上状态值校验，同样是为了减少上下文。这一点最让我受启发的就是 Go Race Detector，简单说就是这个软件会在 Go 运行时额外记录线程获取变量的信息，牺牲了时间和空间，但是一旦遇到 Data Race 就会暴露出来。用锁和 channel都会有一个很 trick 的地方，就是把一个深度嵌套的指针传递给调用方，我的很多这样的 Data Race 都是用 Race Detector 暴露出来的。如果爆出了运行时的 Data Race 再去定位原因，那么耗费的时间和枯燥程度是我不敢想象的。
>关于 Race Detector 还有一些题外话：使用它的时候我很唏嘘，因为回想起了之前工作待过的一个项目组，那是一个整体抗拒打日志，更抗拒自动化测试的地方。每次出了线上 bug，复盘听到最多的就是”你要多想“、”你要让人 review“、”我们再加一道（手工去做的）流程“。我不禁想起了明朝因为人力太便宜所以不愿意大规模推广纺织机的段子。而 Race Detector 背后站立的更多是一种编程的理念，也是推动人类科技进步的力量：”让人来做人适合做的事，让程序来做程序适合做的事“，或者说”自动化“。