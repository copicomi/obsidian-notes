# 10.8 数据分片（Protection Group）

这一部分讨论，Aurora 如何处理大型数据库。目前为止，我们已经知道 Aurora 将自己的数据分布在 6 个副本上，每一个副本都是一个计算机，上面挂了 1-2 块磁盘。但是如果只是这样的话，我们不能拥有一个数据大小大于单个机器磁盘空间的数据库。因为虽然我们有 6 台机器，但是并没有为我们提供 6 倍的存储空间，每个机器存储的都是相同的数据。如果我使用的是 SSD，我可以将数 TB 的数据存放于单台机器上，但是我不能将数百 TB 的数据存放于单台机器上。

为了能支持超过 10TB 数据的大型数据库。Amazon 的做法是将数据库的数据，分割存储到多组存储服务器上，每一组都是 6 个副本，分割出来的每一份数据是 10GB。所以，如果一个数据库需要 20GB 的数据，那么这个数据库会使用 2 个 PG（Protection Group），其中一半的 10GB 数据在一个 PG 中，包含了 6 个存储服务器作为副本，另一半的 10GB 数据存储在另一个 PG 中，这个 PG 可能包含了不同的 6 个存储服务器作为副本。

![](<../assets/image (345).png>)

因为 Amazon 运行了大量的存储服务器，这些服务器一起被所有的 Aurora 用户所使用。两组 PG 可能使用相同的 6 个存储服务器，但是通常来说是完全不同的两组存储服务器。随着数据库变大，我们可以有更多的 Protection Group。

这里有一件有意思的事情，你可以将磁盘中的 data page 分割到多个独立的 PG 中，比如说奇数号的 page 存在 PG1，偶数号的 page 存在 PG2。如果可以根据 data page 做 sharding，那是极好的。

Sharding 之后，Log 该如何处理就不是那么直观了。如果有多个 Protection Group，该如何分割 Log 呢？答案是，当 Aurora 需要发送一个 Log 条目时，它会查看 Log 所修改的数据，并找到存储了这个数据的 Protection Group，并把 Log 条目只发送给这个 Protection Group 对应的 6 个存储服务器。这意味着，每个 Protection Group 只存储了部分 data page 和所有与这些 data page 关联的 Log 条目。所以每个 Protection Group 存储了所有 data page 的一个子集，以及这些 data page 相关的 Log 条目。

如果其中一个存储服务器挂了，我们期望尽可能快的用一个新的副本替代它。因为如果 4 个副本挂了，我们将不再拥有 Read Quorum，我们也因此不能创建一个新的副本。所以我们想要在一个副本挂了以后，尽可能快的生成一个新的副本。表面上看，每个存储服务器存放了某个数据库的某个某个 Protection Group 对应的 10GB 数据，但实际上每个存储服务器可能有 1-2 块几 TB 的磁盘，上面存储了属于数百个 Aurora 实例的 10GB 数据块。所以在存储服务器上，可能总共会有 10TB 的数据，当它故障时，它带走的不仅是一个数据库的 10GB 数据，同时也带走了其他数百个数据库的 10GB 数据。所以生成的新副本，不是仅仅要恢复一个数据库的 10GB 数据，而是要恢复存储在原来服务器上的整个 10TB 的数据。我们来做一个算术，如果网卡是 10Gb/S，通过网络传输 10TB 的数据需要 8000 秒。这个时间太长了，我们不想只是坐在那里等着传输。所以我们不想要有这样一种重建副本的策略：找到另一台存储服务器，通过网络拷贝上面所有的内容到新的副本中。我们需要的是一种快的多的策略。

Aurora 实际使用的策略是，对于一个特定的存储服务器，它存储了许多 Protection Group 对应的 10GB 的数据块。对于 Protection Group A，它的其他副本是 5 个服务器。

![](<../assets/image (346).png>)

或许这个存储服务器还为 Protection Group B 保存了数据，但是 B 的其他副本存在于与 A 没有交集的其他 5 个服务器中（虽然图中只画了 4 个）。

![](<../assets/image (347).png>)

类似的，对于所有的 Protection Group 对应的数据块，都会有类似的副本。这种模式下，如果一个存储服务器挂了，假设上面有 100 个数据块，现在的替换策略是：找到 100 个不同的存储服务器，其中的每一个会被分配一个数据块，也就是说这 100 个存储服务器，每一个都会加入到一个新的 Protection Group 中。所以相当于，每一个存储服务器只需要负责恢复 10GB 的数据。所以在创建新副本的时候，我们有了 100 个存储服务器（下图中下面那 5 个空白的）。

![](<../assets/image (348).png>)

对于每一个数据块，我们会从 Protection Group 中挑选一个副本，作为数据拷贝的源。这样，对于 100 个数据块，相当于有了 100 个数据拷贝的源。之后，就可以并行的通过网络将 100 个数据块从 100 个源拷贝到 100 个目的。

![](<../assets/image (349).png>)

假设有足够多的服务器，这里的服务器大概率不会有重合，同时假设我们有足够的带宽，现在我们可以以 100 的并发，并行的拷贝 1TB 的数据，这只需要 10 秒左右。如果只在两个服务器之间拷贝，正常拷贝 1TB 数据需要 1000 秒左右。

这就是 Aurora 使用的副本恢复策略，它意味着，如果一个服务器挂了，它可以并行的，快速的在数百台服务器上恢复。如果大量的服务器挂了，可能不能正常工作，但是如果只有一个服务器挂了，Aurora 可以非常快的重新生成副本。
