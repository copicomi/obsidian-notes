# 21.8 Receive Livelock

接下来我们看一下今天的[论文](https://pdos.csail.mit.edu/6.828/2020/readings/mogul96usenix.pdf)。因为我们已经介绍了很多论文相关的背景知识，我们直接来看一下论文的图 1。我们之后根据论文中的图来开展讨论。

![](<../assets/image (863).png>)

这张图是一个路由器的性能图。这是一个有两张网卡的路由器，它的工作是从一个网卡接收 packet，再从另一个网卡送出 。X 轴是接收速率，也就是接收端网卡的收到 packet 的速率。Y 轴是发送速率，也就是观察到的发送端网卡发送 packet 的速率。我们关心的是实心圆对应的曲线，它先上升，再下降。所以即使还不知道任何上下文，看到这个图之后我们会问自己，为什么这个曲线先上升，再下降？曲线的转折点有什么特殊之处？是什么决定了曲线的上升斜率和下降斜率？即使不知道任何背景知识，我们还是可以问出这么多问题。

![](<../assets/image (791).png>)

首先，为什么这条曲线开始会上升？

> 学生回答：在到达处理的瓶颈之前，路由器可以处理更多的接收方向的 packet，也可以处理更多的发送发向的 packet。

完全正确，在出现错误之前，对于每个接收到的 packet，路由器都可以转发出去。比如说当 packet 以 2000pps 的速度接收时，路由器直接将 packet 从输入网卡拷贝到输出网卡，所以路由器的发送速率与接收速率一样，都是 2000pps，所以这里 X 轴与 Y 轴的值相等。这种状态一直保持，直到曲线到达转折点。

那么为什么曲线不是一直上升的呢？

> 学生回答：是不是因为中断不能被处理导致的？
>
> Robert 教授：这个其实是为什么曲线会下降的原因。我这里的问题是为什么曲线在某个点之后就不再上升了。假设这里的设计是合理的，对于一个合理的系统，对应的曲线会一直上升吗？
>
> 学生回答：我认为不会，就算系统能足够快的处理 packet，对于足够多的 packet，还是可能触发系统的瓶颈。

是的，CPU 的算力并不是无限的，CPU 最多每秒执行一定数量的指令。对于每个 packet，IP 软件会查看 packet 的 header，检查校验和，根据目的地址查找转发表等等，这个过程会消耗数百甚至数千条 CPU 指令时间来处理一个 packet。所以，我们不能期望曲线能一直向上走，它必然会在某个位置停止向上。

上面的图中，曲线在 5000 的位置就停止不再上升了，这告诉我们这台机器处理每个 packet 要消耗 200 微秒。所以，曲线的转折点隐含的包含了处理一个 packet 需要的时间信息。虽然这只是一个猜想，但是通常与真实的结果非常相近。或许我们可以修改软件使其更加的高效，我们可以优化到处理每个 packet 只需要 150 微秒，我们或许可以将曲线的转折点向上移一些，但是在到达了这台机器每秒能处理的 packet 数量的极限时，我们还是会到达曲线的转折点。

除了 CPU 的性能，还有一些不是必然存在的瓶颈需要注意一下。最明显的一个就是网络的性能。如果你使用的网络只有 10Mb/s，那么底层的网路硬件最多就能按照这个速率传输数据，这也有可能构成一个限制。所以也有可能是因为网络传输的速率决定了曲线的顶点是在 5000pps 这个位置。论文中并没有说明究竟是 CPU 还是网速是这里的限制因素，但是对于一个 10Mb/s 的网络，如果你传输小包的话，是可以达到 10-15 Kpps，这实际上是网线的能达到的极限，而上图中转折点对应的 5Kpps 远小于 10-15Kpps，所以几乎可以确定限制是来自 CPU 或者内存，而不是网络本身。

在一个设计良好的路由器中，如果处理每个 packet 要 200 微秒，那么我们期望看到的是不论负载多高，路由器至少每秒能处理 5000 个 packet。所以我们期望看到的曲线在 5000pps 之后是一条水平线，路由器每秒处理 5000 个 packet，并丢弃掉其他的 packet。

![](<../assets/image (798).png>)

但是我们实际拥有的曲线会更加的糟糕，当收到的 packets 超过 5000pps 时，成功转发的 packets 随着收到的 packet 的增多反而趋向于 0。为什么曲线会下降呢？前面有同学已经提到了。

论文作者给出的原因是，随着 packet 接收速率的增加，每个收到的 packet 都会生成一个中断，而这里的中断的代价非常高，因为中断涉及到 CPU 将一个 packet 从网卡拷贝到主机的内存中。如果我们知道 packet 将会以 10K 每秒的速率到达，并且我们知道我们不能处理这么多 packet，那么我们可以期望的最好结果就是每秒转发 5000 个 packet，并且丢弃 5000 个 packet 之外的其他 packet。但是实际上，5000 个 packet 之外的其他 packet，每个都生成了一个昂贵的中断，收到的 packet 越多，生成的中断就越多。而中断有更高的优先级，所以每一个额外的 packet 都会消耗 CPU 时间，导致更少的 CPU 时间可以用来完成 packet 的转发。最后，100%的 CPU 时间都被消耗用来处理网卡的输入中断，CPU 没有任何时间用来转发 packet。

这里曲线的下降被称为中断的 Livelock，这是一个在很多系统中都会出现的现象。这里背后的原因是有两个独立的任务，比如这里的两个任务是输入中断和转发 packet 程序。由于调度的策略，输入中断的优先级更高，使得转发 packet 的任务可能分配不到任何 CPU 时间。几乎在任何需要处理输入的系统中，如果输入速率过高，都有可能出现 Livelock。Livelock 不仅会因为 CPU 耗尽而发生，也可能是其他原因，比如说网卡的 DMA 耗尽了 RAM 的处理时间，那么网卡占据了 RAM 导致 CPU 不能使用 RAM。所以，即使你拥有大量的 CPU 空闲时间，还是有可能触发 Livelock。不管怎样，这曲线的下降被称为 Livelock。

![](<../assets/image (772).png>)

你或许会问，不能处理的 packet 最后怎么样了？我们回想一下网络协议软件的结构，网卡会通知网卡的接收中断，接收中断将 packet 拷贝到队列缓存中，之后会有一个线程处理队列缓存中的 packet。

![](<../assets/image (803).png>)

所以 packet 会在队列缓存中丢失。队列缓存有一个最大的长度，至少 RAM 的大小是有限制大，但是队列缓存的大小会远小于 RAM 的大小。如果网卡的接收中断从网卡获得了一个 packet，并且发现队列缓存的长度已经是最长了，接收中断程序会丢弃 packet。
