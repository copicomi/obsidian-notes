# 23.6 RCU 用例代码

为了巩固前面介绍的内容，接下来看一段使用了 RCU 的简单代码。上半段是读取被 RCU 保护的链表 ，下半段代码是替换链表的第一个元素。

![](<../assets/image (486).png>)

数据读取位于 rcu_read_lock 和 rcu_read_unlock 之间，这两个函数几乎不做任何事情。rcu_read_lock 会设置一个标志位，表明如果发生了定时器中断，请不要执行 context switch，因为接下来要进入 RCU critical 区域。所以 rcu_read_lock 会设置一个标志位来阻止定时器中断导致的 context switch，中断或许还会发生，但是不会导致 context switch（注，也就是线程切换）。rcu_read_unlock 会取消该标志位。所以这是一个集成在 RCU critical 区域的计数器。rcu_read_lock 和 rcu_read_unlock 因为几乎不做任何工作所以极其的快（注，这里有个问题，23.2 中描述的读写锁慢的原因是因为在读数据的时候引入了写计数器的操作，这里同样也是需要额外的写操作，为什么这里不会有问题？这是因为读写锁的计数器是所有 CPU 共享的，而这里的标志位是针对每个 CPU 的，所以修改这里的标志位并不会引起 CPU 之间的缓存一致消息）。

其中的 while 循环会扫描链表，rcu_dereference 函数会插入 memory barrier，它首先会从内存中拷贝 e，触发一个 memory barrier，之后返回指向 e 的指针。之后我们就可以读取 e 指针指向的数据内容，并走向下一个链表元素。数据读取部分非常简单。

数据写入部分更复杂点。

- RCU 并不能帮助数据写入者之间避免相互干扰，所以必须有一种方法能确保一次只能有一个数据写入者更新链表。这里我们假设我们将使用普通的 spinlock，所以最开始数据写入者获取锁。
- 如果我们要替换链表的第一个元素，我们需要保存先保存链表第一个元素的拷贝，因为最后我们需要释放它，所以有 old=head。
- 接下来的代码执行的是之前介绍的内容，首先是分配一个全新的链表元素，之后是设置该链表元素的内容，设置该链表元素的 next 指针指向旧元素的 next 指针。
- 之后的 rcu_assign_pointer 函数会设置一个 memory barrier，以确保之前的所有写操作都执行完，再将 head 指向新分配的链表元素 e。
- 之后就是释放锁。
- 之后调用 synchronize_rcu 确保任何一个可能持有了旧的链表元素的 CPU 都执行一次 context switch，因此这些 CPU 会放弃指向旧链表元素的指针。
- 最后是释放旧的链表元素。

这里有件事情需要注意，在数据读取代码中，我们可以在循环中查看链表元素，但是我们不能将链表元素返回。例如，我们使用 RCU 的时候，不能写一个 list_lookup 函数来返回链表元素，也不能返回指向链表元素中数据的指针，也就是不能返回嵌入在链表元素中的字符串。我们必须只在 RCU critical 区域内查看被 RCU 保护的数据，如果我们写了一个通用的函数返回链表元素，或许我们能要求这个函数的调用者也遵循一些规则，但是函数的调用者还是可能会触发 context switch。如果我们在函数的调用者返回之前调用了 rcu_read_unlock，这将会违反 23.5 中的规则 1，因为现在定时器中断可以迫使 context switch，而被 RCU 保护的数据指针仍然被持有者。所以使用 RCU 的确会向数据读取者增加一些之前并不存在的限制。

> 学生提问：这样是不是说我们不可能返回下标是 i 的元素所包含的内容？
>
> Robert 教授：可以返回一个拷贝，如果 e->x 是个字符串，那么我们可以返回一个该字符串的拷贝，这是没有问题的。但是如果我们直接返回一个指针指向 e->x，那就违反了 RCU 规则。实际上返回 e 中的任何指针都是错误的，因为我们不能在持有指向 RCU 保护数据的指针时，发生 context switch。通常的习惯是直接在 RCU critical 区域内使用这些数据。

接下来我将再简短的介绍性能。如果你使用 RCU，数据读取会非常的快，除了读取数据本身的开销之外就几乎没有别的额外的开销了。如果你的链表有 10 亿个元素，读取链表本身就要很长的时间，但是这里的时间消耗并不是因为同步（注，也就是类似加锁等操作）引起的。所以你几乎可以认为 RCU 对于数据读取者来说没有额外的负担。唯一额外的工作就是在 rcu_read_lock 和 rcu_read_unlock 里面设置好不要触发 context switch，并且在 rcu_dereference 中设置 memory barrier，这些可能会消耗几十个 CPU cycle，但是相比锁来说代价要小的多。

对于数据写入者，性能会更加的糟糕。首先之前使用锁的时候所有的工作仍然需要做，例如获取锁和释放锁。其次，现在还有了一个可能非常耗时的 synchronize_rcu 函数调用。实际上在 synchronize_rcu 内部会出让 CPU，所以代码在这不会通过消耗 CPU 来实现等待，但是它可能会消耗大量时间来等待其他所有的 CPU 核完成 context switch。所以基于数据写入时的多种原因，和数据读取时的工作量，数据写入者需要消耗更多的时间完成操作。如果数据读取区域很短（注，这样就可以很快可以恢复 context switch），并且数据写入并没有很多，那么数据写入慢一些也没关系。所以当人们将 RCU 应用到内核中时，必须要做一些性能测试来确认使用 RCU 是否能带来好处，因为这取决于实际的工作负载。

> 70:00 - 73:20（不相关的问题，故略过）
