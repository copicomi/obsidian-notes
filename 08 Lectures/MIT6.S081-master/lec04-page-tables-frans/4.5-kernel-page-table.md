# 4.5 Kernel Page Table

接下来，我们看一下在 XV6 中，page table 是如何工作的？首先我们来看一下 kernel page 的分布。下图就是内核中地址的对应关系，左边是内核的虚拟地址空间，右边上半部分是物理内存或者说是 DRAM，右边下半部分是 I/O 设备。接下来我会首先介绍右半部分，然后再介绍左半部分。

![](<../assets/image (345).png>)

图中的右半部分的结构完全由硬件设计者决定。如你们上节课看到的一样，当操作系统启动时，会从地址 0x80000000 开始运行，这个地址其实也是由硬件设计者决定的。具体的来说，如果你们看一个主板，

![](<../assets/image (238).png>)

中间是 RISC-V 处理器，我们现在知道了处理器中有 4 个核，每个核都有自己的 MMU 和 TLB。处理器旁边就是 DRAM 芯片。

![](<../assets/image (404).png>)

主板的设计人员决定了，在完成了虚拟到物理地址的翻译之后，如果得到的物理地址大于 0x80000000 会走向 DRAM 芯片，如果得到的物理地址低于 0x80000000 会走向不同的 I/O 设备。这是由这个主板的设计人员决定的物理结构。如果你想要查看这里的物理结构，你可以阅读主板的手册，手册中会一一介绍物理地址对应关系。

![](<../assets/image (244).png>)

![](<../assets/image (192).png>)

首先，地址 0 是保留的，地址 0x10090000 对应以太网，地址 0x80000000 对应 DDR 内存，处理器外的易失存储（Off-Chip Volatile Memory），也就是主板上的 DRAM 芯片。所以，在你们的脑海里应该要记住这张主板的图片，即使我们接下来会基于你们都知道的 C 语言程序---QEMU 来做介绍，但是最终所有的事情都是由主板硬件决定的。

> 学生提问：当你说这里是由硬件决定的，硬件是特指 CPU 还是说 CPU 所在的主板？
>
> Frans 教授：CPU 所在的主板。CPU 只是主板的一小部分，DRAM 芯片位于处理器之外。是主板设计者将处理器，DRAM 和许多 I/O 设备汇总在一起。对于一个操作系统来说，CPU 只是一个部分，I/O 设备同样也很重要。所以当你在写一个操作系统时，你需要同时处理 CPU 和 I/O 设备，比如你需要向互联网发送一个报文，操作系统需要调用网卡驱动和网卡来实际完成这个工作。

回到最初那张图的右侧：物理地址的分布。可以看到最下面是未被使用的地址，这与主板文档内容是一致的（地址为 0）。地址 0x1000 是 boot ROM 的物理地址，当你对主板上电，主板做的第一件事情就是运行存储在 boot ROM 中的代码，当 boot 完成之后，会跳转到地址 0x80000000，操作系统需要确保那个地址有一些数据能够接着启动操作系统。

![](<../assets/image (205).png>)

这里还有一些其他的 I/O 设备：

- PLIC 是中断控制器（Platform-Level Interrupt Controller）我们下周的课会讲。
- CLINT（Core Local Interruptor）也是中断的一部分。所以多个设备都能产生中断，需要中断控制器来将这些中断路由到合适的处理函数。
- UART0（Universal Asynchronous Receiver/Transmitter）负责与 Console 和显示器交互。
- VIRTIO disk，与磁盘进行交互。

地址 0x02000000 对应 CLINT，当你向这个地址执行读写指令，你是向实现了 CLINT 的芯片执行读写。这里你可以认为你直接在与设备交互，而不是读写物理内存。

> 学生提问：确认一下，低于 0x80000000 的物理地址，不存在于 DRAM 中，当我们在使用这些地址的时候，指令会直接走向其他的硬件，对吗？
>
> Frans 教授：是的。高于 0x80000000 的物理地址对应 DRAM 芯片，但是对于例如以太网接口，也有一个特定的低于 0x80000000 的物理地址，我们可以对这个叫做内存映射 I/O（Memory-mapped I/O）的地址执行读写指令，来完成设备的操作。
>
> &#x20;学生提问：为什么物理地址最上面一大块标为未被使用？
>
> Frans 教授：物理地址总共有 2^56 那么多，但是你不用在主板上接入那么多的内存。所以不论主板上有多少 DRAM 芯片，总是会有一部分物理地址没有被用到。实际上在 XV6 中，我们限制了内存的大小是 128MB。
>
> 学生提问：当读指令从 CPU 发出后，它是怎么路由到正确的 I/O 设备的？比如说，当 CPU 要发出指令时，它可以发现现在地址是低于 0x80000000，但是它怎么将指令送到正确的 I/O 设备？
>
> Frans 教授：你可以认为在 RISC-V 中有一个多路输出选择器（demultiplexer）。

接下来我会切换到第一张图的左边，这就是 XV6 的虚拟内存地址空间。当机器刚刚启动时，还没有可用的 page，XV6 操作系统会设置好内核使用的虚拟地址空间，也就是这张图左边的地址分布。

因为我们想让 XV6 尽可能的简单易懂，所以这里的虚拟地址到物理地址的映射，大部分是相等的关系。比如说内核会按照这种方式设置 page table，虚拟地址 0x02000000 对应物理地址 0x02000000。这意味着左侧低于 PHYSTOP 的虚拟地址，与右侧使用的物理地址是一样的。

![](<../assets/image (354).png>)

所以，这里的箭头都是水平的，因为这里是完全相等的映射。

除此之外，这里还有两件重要的事情：

第一件事情是，有一些 page 在虚拟内存中的地址很靠后，比如 kernel stack 在虚拟内存中的地址就很靠后。这是因为在它之下有一个未被映射的 Guard page，这个 Guard page 对应的 PTE 的 Valid 标志位没有设置，这样，如果 kernel stack 耗尽了，它会溢出到 Guard page，但是因为 Guard page 的 PTE 中 Valid 标志位未设置，会导致立即触发 page fault，这样的结果好过内存越界之后造成的数据混乱。立即触发一个 panic（也就是 page fault），你就知道 kernel stack 出错了。同时我们也又不想浪费物理内存给 Guard page，所以 Guard page 不会映射到任何物理内存，它只是占据了虚拟地址空间的一段靠后的地址。

同时，kernel stack 被映射了两次，在靠后的虚拟地址映射了一次，在 PHYSTOP 下的 Kernel data 中又映射了一次，但是实际使用的时候用的是上面的部分，因为有 Guard page 会更加安全。

![](<../assets/image (258).png>)

这是众多你可以通过 page table 实现的有意思的事情之一。你可以向同一个物理地址映射两个虚拟地址，你可以不将一个虚拟地址映射到物理地址。可以是一对一的映射，一对多映射，多对一映射。XV6 至少在 1-2 个地方用到类似的技巧。这的 kernel stack 和 Guard page 就是 XV6 基于 page table 使用的有趣技巧的一个例子。

第二件事情是权限。例如 Kernel text page 被标位 R-X，意味着你可以读它，也可以在这个地址段执行指令，但是你不能向 Kernel text 写数据。通过设置权限我们可以尽早的发现 Bug 从而避免 Bug。对于 Kernel data 需要能被写入，所以它的标志位是 RW-，但是你不能在这个地址段运行指令，所以它的 X 标志位未被设置。（注，所以，kernel text 用来存代码，代码可以读，可以运行，但是不能篡改，kernel data 用来存数据，数据可以读写，但是不能通过数据伪装代码在 kernel 中运行）

![](<../assets/image (260).png>)

> 学生提问：对于不同的进程会有不同的 kernel stack 吗？
>
> Frans：答案是的。每一个用户进程都有一个对应的 kernel stack
>
> 学生提问：用户程序的虚拟内存会映射到未使用的物理地址空间吗？
>
> Frans 教授：在 kernel page table 中，有一段 Free Memory，它对应了物理内存中的一段地址。

![](<../assets/image (246).png>)

> XV6 使用这段 free memory 来存放用户进程的 page table，text 和 data。如果我们运行了非常多的用户进程，某个时间点我们会耗尽这段内存，这个时候 fork 或者 exec 会返回错误。
>
> 同一个学生提问：这就意味着，用户进程的虚拟地址空间会比内核的虚拟地址空间小的多，是吗？
>
> Frans 教授：本质上来说，两边的虚拟地址空间大小是一样的。但是用户进程的虚拟地址空间使用率会更低。
>
> 学生提问：如果多个进程都将内存映射到了同一个物理位置，这里会优化合并到同一个地址吗？
>
> Frans 教授：XV6 不会做这样的事情，但是 page table 实验中有一部分就是做这个事情。真正的操作系统会做这样的工作。当你们完成了 page table 实验，你们就会对这些内容更加了解。

（以下问答来自这节课程结束部分，因为内容相关就移过来了）

> 学生提问：每个进程都会有自己的 3 级树状 page table，通过这个 page table 将虚拟地址翻译成物理地址。所以看起来当我们将内核虚拟地址翻译成物理地址时，我们并不需要 kernel 的 page table，因为进程会使用自己的树状 page table 并完成地址翻译（注，不太理解这个问题点在哪）。
>
> Frans 教授：当 kernel 创建了一个进程，针对这个进程的 page table 也会从 Free memory 中分配出来。内核会为用户进程的 page table 分配几个 page，并填入 PTE。在某个时间点，当内核运行了这个进程，内核会将进程的根 page table 的地址加载到 SATP 中。从那个时间点开始，处理器会使用内核为那个进程构建的虚拟地址空间。
>
> 同一个学生提问：所以内核为进程放弃了一些自己的内存，但是进程的虚拟地址空间理论上与内核的虚拟地址空间一样大，虽然实际中肯定不会这么大。
>
> Frans 教授：是的，下图是用户进程的虚拟地址空间分布，与内核地址空间一样，它也是从 0 到 MAXVA。

![](<../assets/image (211).png>)

> 它有由内核设置好的，专属于进程的 page table 来完成地址翻译。

> 学生提问：但是我们不能将所有的 MAXVA 地址都使用吧？
>
> Frans 教授：是的我们不能，这样我们会耗尽内存。大多数的进程使用的内存都远远小于虚拟地址空间。
