# 22.4 CPU caches

接下来我将介绍 Micro-Architectural 的另一个部分，也就是缓存。我知道大家都知道 CPU 有 cache，但是缓存或多或少应该是也透明的。让我画个图描述一下 cache，因为我认为 cache 与 Meltdown 最相关。

首先，你有 CPU 核，这是 CPU 的一部分，它会解析指令，它包含了寄存器，它有加法单元，除法单元等等。所以这是 CPU 的执行部分。

![](<../assets/image (159).png>)

当 CPU 核需要执行 load/store 指令时，CPU 核会与内存系统通信。内存系统一些 cache 其中包含了数据的缓存。首先是 L1 data cache，它或许有 64KB，虽然不太大，但是它特别的快。如果你需要的数据在 L1 cache 中，只通过几个 CPU cycle 就可以将数据取回。L1 cache 的结构包含了一些线路，每个线路持有了可能是 64 字节的数据。这些线路是个表单，它们通过虚拟内存地址索引。如果一个虚拟内存地址在 cache 中，并且 cache 为这个虚拟内存地址持有了数据，那么实际中可以认为 L1 cache 中也包含了来自对应于虚拟内存地址的 PTE 的权限。

![](<../assets/image (61).png>)

L1 cache 是一个表单，当 CPU 核执行 load 指令时，首先硬件会检查 L1 cache 是否包含了匹配 load 指令的虚拟内存地址，如果有的话，CPU 会直接将 L1 cache 中的数据返回，这样可以很快完成指令。

如果不在 L1 cache，那么数据位于物理内存中，所以现在我们需要物理内存地址，这里需要 Translation Lookaside Buffer（TLB），TLB 是 PTE 的缓存。现在我们会检查 load 指令中的虚拟内存地址是否包含在 TLB 中。如果不在 TLB，我们就需要做大量的工作，我们需要从内存中读取相关的 PTE。让我们假设 TLB 中包含了虚拟内存地址对应的物理内存 Page 地址，我们就可以获取到所需要的物理内存地址。通常来说会有一个更大的 cache（L2 cache），它是由物理内存地址索引。

![](<../assets/image (41).png>)

现在通过 TLB 我们找到了物理内存地址，再通过 L2 cache，我们有可能可以获取到数据。如果我们没有在 L2 cache 中找到物理内存地址对应的数据。我们需要将物理内存地址发送给 RAM 系统。这会花费很长的时间，当我们最终获得了数据时，我们可以将从 RAM 读取到的数据加入到 L1 和 L2 cache 中，最终将数据返回给 CPU 核。

![](<../assets/image (147).png>)

以上就是 CPU 的 cache。如果 L1 cache 命中的话可能只要几个 CPU cycle，L2 cache 命中的话，可能要几十个 CPU cycle，如果都没有命中最后需要从内存中读取那么会需要几百个 CPU cycle。一个 CPU cycle 在一个 2GHZ 的 CPU 上花费 0.5 纳秒。所以拥有 cache 是极其有利的，如果没有 cache 的话，你将会牺牲掉几百倍的性能。所以 cache 对于性能来说是非常关键的。

在 Meltdown Attack 的目标系统中，如果我们运行在用户空间，L1 和 L2 cache 可以既包含用户数据，也包含内核数据。L2 cache 可以包含内核数据因为它只是物理内存地址。L1 cache 有点棘手，因为它是虚拟内存地址，当我们更换 Page Table 时，L1 cache 的内容不再有效。因为更换 Page Table 意味着虚拟内存地址的意义变了，所以这时你需要清空 L1 cache。不过实际中会有更多复杂的细节，可以使得你避免清空 L1 cache。

论文中描述的操作系统并没有在内核空间和用户空间之间切换的时候更换 Page Table，因为两个空间的内存地址都映射在同一个 Page Table 中了。这意味着我们不必清空 L1 cache，也意味着 L1 cache 会同时包含用户和内核数据，这使得系统调用更快。如果你执行系统调用，当系统调用返回时，L1 cache 中还会有有用的用户数据，因为我们在这个过程中并没与更换 Page Table。所以，当程序运行在用户空间时，L1 cache 中也非常有可能有内核数据。L1 cache 中的权限信息拷贝自 TLB 中的 PTE，如果用户空间需要访问内核内存数据，尽管内核数据在 L1 cache 中，你也不允许使用它，如果使用的话会触发 Page Fault。

尽管 Micro-Architectural 的初衷是完全透明，实际中不可能做到，因为 Micro-Architectural 优化的意义在于提升性能，所以至少从性能的角度来说，它们是可见的。也就是说你可以看出来你的 CPU 是否有 cache，因为如果没有的话，它会慢几百倍。除此之外，如果你能足够精确测量时间，那么在你执行一个 load 指令时，如果 load 在几个 CPU cycle 就返回，数据必然是在 cache 中，如果 load 在几百个 CPU cycle 返回，数据可能是从 RAM 中读取，如果你能达到 10 纳秒级别的测量精度，你会发现这里区别还是挺大的。所以从性能角度来说，Micro-Architectural 绝对不是透明的。我们现在讨论的分支预测，cache 这类功能至少通过时间是间接可见的。

所以尽管 Micro-Architectural 设计的细节都是保密的，但是很多人对它都有强烈的兴趣，因为这影响了很多的性能。比如说编译器作者就知道很多 Micro-Architectural 的细节，因为很多编译器优化都基于人们对于 CPU 内部工作机制的猜测。实际中，CPU 制造商发布的优化手册披露了一些基于 Micro-Architectural 的技巧，但是他们很少会介绍太多细节，肯定没有足够的细节来理解 Meltdown 是如何工作的。所以 Micro-Architectural 某种程度上说应该是透明的、隐藏的、不可见的，但同时很多人又知道一些随机细节。

（以下内容来自 82:10 - 86:30，因为相关故移过来了）

> 学生提问：L1 cache 是每个 CPU 都有一份，L2 cache 是共享的对吧？
>
> Robert 教授：不同 CPU 厂商，甚至同一个厂商的不同型号 CPU 都有不同的 cache 结构。今天普遍的习惯稍微有点复杂，在一个多核 CPU 上，每一个 CPU 核都有一个 L1 cache，它离 CPU 核很近，它很快但是很小。每个 CPU 核也还有一个大点的 L2 cache。除此之外，通常还会有一个共享的 L3 cache。

![](<../assets/image (138).png>)

> 另一种方式是所有的 L2 cache 结合起来，以方便所有的 CPU 共用 L2 cache，这样我可以非常高速的访问我自己的 L2 cache，但是又可以稍微慢的访问别的 CPU 的 L2 cache，这样有效的 cache 会更大。

![](<../assets/image (15).png>)

> 所以通常你看到的要么是三级 cache，或者是两级 cache 但是 L2 cache 是合并在一起的。典型场景下，L2 和 L3 是物理内存地址索引，L1 是虚拟内存地址索引。
>
> 学生提问：拥有物理内存地址的缓存有什么意义？
>
> Robert 教授：如果同一个数据被不同的虚拟内存地址索引，虚拟内存地址并不能帮助你更快的找到它。而 L2 cache 与虚拟内存地址无关，不管是什么样的虚拟内存地址，都会在 L2 cache 中有一条物理内存地址记录。
>
> 学生提问：MMU 和 TLB 这里位于哪个位置？
>
> Robert 教授：我认为在实际中最重要的东西就是 TLB，并且我认为它是与 L1 cache 并列的。如果你 miss 了 L1 cache，你会查看 TLB 并获取物理内存地址。MMU 并不是一个位于某个位置的单元，它是分布在整个 CPU 上的。

![](<../assets/image (14).png>)

> 学生提问：但是 MMU 不是硬件吗？
>
> Robert 教授：是的，这里所有的东西都是硬件。CPU 芯片有数十亿个晶体管，所以尽管是硬件，我们讨论的也是使用非常复杂的软件设计的非常复杂的硬件。所以 CPU 可以做非常复杂和高级的事情。所以是的，它是硬件，但是它并不简单直观。
>
> 学生提问：Page Table 的映射如果没有在 TLB 中命中的话，还是要走到内存来获取数据，对吧？
>
> Robert 教授：从 L2 cache 的角度来说，TLB miss 之后的查找 Page Table 就是访问物理内存，所以 TLB 需要从内存中加载一些内存页，因为这就是加载内存，这些内容可以很容易将 Page Table 的内容缓存在 L2 中。
