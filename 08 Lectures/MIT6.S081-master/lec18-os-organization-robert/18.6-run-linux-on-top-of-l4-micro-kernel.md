# 18.6 Run Linux on top of L4 micro kernel

前一节对于 IPC 的优化使得人们开始认真考虑使用微内核替代 monolithic kernel。然而，这里仍然有个问题，即使 IPC 很快了，操作系统的剩余部分从哪里去获取？现在的微内核大概只有一个完整操作系统的百分之几，我们该怎么处理操作系统剩下的部分？这个问题通常会在一些有着相对较少资源的学校研究项目中被问到，我们需要从某个地方获取到所有这些用户空间服务。

实际上在一些特殊的应用场合，以上的问题并不是问题，比如说我们运行的一些设备的控制器，例如车里的点火控制器，只运行了几千行代码，它并且不需要一个文件系统，这样我们就只需要很少的用户空间内容，微内核也特别适合这种应用程序。但是微内核项目发起时，人们非常有雄心壮志，人们想的是完全替换操作系统，人们希望可以构建一些运行在工作站，服务器等各种地方的微内核操作系统，并取代大的 monolithic kernel。对于这种场景，你需要一个传统操作系统所需要的所有内容。

一种可能是，重新以微内核的方式，以大量的进程实现所有的内容。实际上有项目在这么做，但是这涉及到大量的工作。具体的说，比如我想要使用笔记本电脑，我的电脑必须要有 emacs 和我最喜欢的 C 编译器，否则我肯定不会用你的操作系统。这意味着，微内核要想获得使用，它必须支持现有的应用程序，它必须兼容或者提供相同的系统调用或者更高层的服务接口，它必须能够完全兼容一些现有的操作系统，例如 Unix，Linux，这样人们才愿意切换到微内核。所以这些微内核项目都面临一个具体的问题，它们怎么兼容一些为 Linux，Windows 写的应用程序？对于论文中提到的项目，也就是 L4，对标的是 Linux。与其写一些完全属于自己的新的用户空间服务，并模仿 Linux，论文中决定采用一种容易的多的方法，其实许多项目也都采用了这种方法，也就是简单的将一个现有的 monolithic kernel 运行在微内核之上，而不是重新实现一些新的东西。这就是今天论文要介绍的内容。

在今天[论文](https://pdos.csail.mit.edu/6.828/2020/readings/microkernel.pdf)的讨论中，L4 微内核位于底部，但是同时，一个完整的 Linux 作为一个巨大的服务运行在用户空间进程中。听起来有点奇怪，一般的 kernel 都是运行在硬件之上，而现在 Linux kernel 是一个用户空间进程。

![](<../assets/image (42).png>)

实际上，如你在 QEMU 上运行 XV6 时所见，内核也是运行在用户空间。Linux kernel 不过就是一个程序，对其做一些修改它就可以运行在用户空间，所以现在 Linux 需要被修改。论文中提到需要对 Linux 的底层做一些修改，例如 Linux 中期望能直接修改 Page Table 的内容，读写 CPU 寄存器。Linux 中一部分需要被修改以将它们改成调用 L4 微内核的系统调用，或者发送 IPC，而不是直接访问硬件。但是 Linux 的大部分内容都可以不做修改而直接运行。所以按照这种方式，作为 Linux 的一部分，现在得到了文件系统，网络支持，各种设备驱动等等，而不需要自己实现这些。

![](<../assets/image (47).png>)

这里的实现方式是将 Linux 内核作为一个 L4 Task 运行，每一个 Linux 进程又作为一个独立的 L4 Task 运行。所以当你登录到 Linux 中时，你要它运行一个 Shell 或者 terminal，它会在用户空间创建一个 L4 Task 来运行这个 Linux 程序。所以现在有一个 Task 运行 Linux，以及 N 个 Task 来运行每一个你在 Linux 中启动的进程。

![](<../assets/image (55).png>)

Linux 不会直接修改进程的 Page Table，而是会向 L4 发送正确的 IPC 让 L4 来修改进程的 Page Table。

这里有很多小的改动，其中一个有意思的地方是，当 VI 想要执行一个系统调用时，VI 并不知道它运行在 L4 之上，在上面的方案中，所有的程序都以为它们运行在 Linux 中。当 VI 要执行系统调用时，L4 并不支持，因为 VI 要执行的是 Linux 系统调用而不是 L4 系统调用。所以对于 Linux 进程，会有一个小的库与之关联，这个库会将类似于 fork，exec，pipe，read，write 的系统调用，转换成发送到 Linux kernel Task 的 IPC 消息，并等待 Linux kernel Task 的返回，然后再返回到进程中。从 VI 的角度看起来好像就是从系统调用返回了。所以这些小的库会将系统调用转成发送到 Linux kernel Task 的 IPC 消息。这意味着，如果 Linux kernel Task 没有做其他事情的话，它会在一个 recv 系统调用中等待接收从任何一个进程发来的下一个系统调用请求 IPC。

![](<../assets/image (140).png>)

这导致了这里的 Linux 和普通的 Linux 明显不同的工作方式。在普通的 Linux 中，就像 XV6 一样，会有一个内核线程对应每一个用户空间进程。当用户空间进程调用系统调用时，内核会为这个系统调用运行一个内核线程。并且，在普通的 Linux 中，如果内核在内核线程之间切换，这基本上意味着从一个用户进程切换到另一个用户进程。所以这里 Linux kernel 的内核线程以及当 Linux 完成工作之后要运行的用户进程之间有一对一的关系。

在这里架构中，这种一对一的关系断了，这里的 Linux kernel 运行在一个 L4 线程中。然而，就像 XV6 一样，这个线程会使用与 XV6 中的 context switching 非常相似的技术，在与每个用户进程对应的内核线程之间切换。不过这些内核线程完全是在 Linux 中实现的，与 L4 线程毫无关系，唯一的 L4 线程就是运行了 Linux kernel 的控制线程。

![](<../assets/image (65).png>)

但是哪个用户进程可以运行，是由 L4 决定的。所以在这里的设置中，Linux kernel 或许在内核线程中执行来自 VI 的系统调用，同时，L4 又使得 Shell 在用户空间运行了。这在 XV6 或者 Linux 极不可能发生，在这两个系统中，活跃的内核线程和用户进程有直接的对应关系，而 L4 会运行它喜欢的任何 Task。因为 Linux kernel 中的内核线程都是私有的实现，Linux 可以同时执行不同阶段的多个系统调用，或许一个进程在它的内核线程中在等待磁盘，这时 Linux 可以运行另一个进程的内核线程来处理另一个进程的系统调用。

你或许会想知道为什么不直接使用 L4 线程来实现 Linux 内的内核线程，或者说 Linux 为什么要实现自己内部的内核线程，而不是使用 L4 线程，答案是，

- 在论文发表时，还没有用到多核 CPU 硬件，他们使用的是单核 CPU 硬件。所以在内核中同时运行多个内核线程并没有性能优势，因为只有一个 CPU 核，所以第二个线程不能执行，由于硬件的限制，一次只能执行一个线程。
- 另一个或许是更强大的原因是，在论文发表时，他们使用的 Linux 版本并不支持将 Linux kernel 运行在多个 CPU 核上。所以他们使用的是旧版本的单核 Linux，一次只能期望在内核中使用一个 CPU，它并没有类似于 XV6 的 spinlock，可以使得它能正确的在内核中使用多核。所以在 Linux 内核中使用多个 L4 线程并没有性能优势。如果一定要使用的话，在没有性能优势的前提下，又需要加入 spinlock 和其他的内容来支持并发。所以论文中没有在 Linux 内核使用 L4 线程。

这种架构的一个缺点是，在普通原生的 Linux 中，存在大量复杂的线程调度机制，例如在不同进程上增加优先级，确保调度公平性等等。Linux 可以在你的笔记本上运行这些机制，因为 Linux 控制了哪些进程可以运行在哪些 CPU 核上。但是在这里的架构中，Linux 完全控制不了哪些进程可以运行，因为现在是 L4 而不是 Linux 在完成调度，这些进程都是被 L4 所调度。所以这里的架构失去了 Linux 的调度能力，这是这种架构的缺点，我相信 L4 的后续版本有一些方法能够让 Linux 通知 L4 调度器，来给某个进程更高优先级等等。
