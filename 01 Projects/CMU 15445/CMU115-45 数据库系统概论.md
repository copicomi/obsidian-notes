https://www.bilibili.com/video/BV169QhYZEhn/?p=2&t=1986.976966&vd_source=9d5c1f6340c538765349683259dc7c94

---
# Lecture 1

data model 与 schema 不同x
前者是抽象的数学概念，而后者是有关数据存储结构的编码概念

依旧是分层抽象，不要向用户暴露任何有关数据的组织结构的具体实现

1. 原数据
2. 物理结构（数据编码）
3. 逻辑结构（数据表）
4. 虚拟结构（虚表）
5. 用户层

关系型数据库在透明性这方面，甚至有些极端，她连指针都不允许用户染指，完全把用户当作呆瓜
 
primary key 唯一标识一个实体
foreign key 将不同实体间建立关系

---
# Lecture 4 
## 日志结构存储
[[STTable]] 与 MemTable 结合

写入时修改 mem，当容量已满时将 mem 清空，以日志形式（PUT key-value, DEL key）写入到 STTable

因此在 **insert** 时的开销极小，不需要调整数据结构

而成本主要集中在 SSTable 的维护，需要在后台不断进行压缩与合并

读取时，依次检查 mem 与 SSTable，通过过滤器进行快速查找

> - 与**索引结构存储**的对比
> index 结构需要在插入时维护各种数据结构
> 但读取速度很快

## 存储细节

### 字对齐
考虑 64bit 的 CPU，我们存储的数据应该是 64位对齐的，否则会增加内存读取时间，这一点通过对 page 进行*填充*或*排序*来解决

### 空值
使用 *位图* 或 *特殊值* 来表示

### Big Data
采用*溢出页*来存储，或者进行压缩

### 精确数据
对于浮点数这样的数据类型，运算时有误差，因此我们不会使用 *float/double* 这样现有的类型，而是采用*String + MetaData* 的结构存储内容，并对 *运算符* 进行重写

# Lecture 5

列存储结构，专注于查询速度

## 工作负载
- OLTP: 频繁而简单，事务导向
-  OLAP: 复杂、大量数据，计算导向
-  HTAP: OLTP + OLAP

## DSM
与 **NSM（行存储）** 相对，使用 NSM 做数据分析时，不得不读取整个元组的无用信息，因此考虑 **列存储**

![[Pasted image 20250807143807.png]]

要维护从 data 到 id 的映射
1. 采用定长偏移量
2. 额外记录关联 id（不建议）

DSM 的更新成本相当高，可以在后台运行
Oracle 把它作为数据库副本使用，由底层引擎决定使用 NSM 还是 DSM

可以多个列打包放在一起，以提升空间局部性

**折中的设计总是可以考虑**

## 压缩
三个目标：
1. 保证数据对齐
2. 延迟解压的时刻（不做无用的解压）
3. 无损

使用时，从 disk 读出压缩数据，随后解压到 buffer

对于**重复次数**较多的数据，可以采用*三元组*压缩连续数据

对于**bit**利用低的数据，可以采用*位压缩*，压缩不了的数据存到辅助表

对于**值域**较小的数据，可以采用*位图*压缩数据

对于**变化量**较小的数据，可以采用*偏移量+三元组*压缩数据

对于一般数据，可以采用*字典*进行编码压缩

# Lecture 6

> 为什么使用 buffer pool 而不是 OS 提供的 mmap？
> 1. 事务的原子性：os会隐藏底层细节，导致提前flush
> 2. IO 时延：os读数据时会阻塞进程
> 3. 异常处理：os只会返回中断，增加代码复杂度
> 4. 性能
> 尽管存在解决方案，但基于 mmap 的方案通常类似于 buffer，并且性能更差


# Lecture 7

介绍了线性hash、可扩展hash，略

# Lecture 8

介绍 b+Tree
相关的一些优化策略：
1. 合并重复键，压缩信息
2. 采用类似 LSM 的做法，先惰性存储日志，search 时先查日志，日志表填满时向下拆分
3. insert时可以等效成 key 的前缀，因为中间节点的key不影响正确性
4. SIMD：并行读取多个节点（向量指令）
5. 对于热点页面，可以将 leaf 中的指针替换成真实地址（而不需要向 buffer 请求）
6. 初始化时，从 leaf 自底向上构建

# Lecture 9

## bloom filter

快速回答某个 key **不存在**于集合中

采用位图 + hash

![[Pasted image 20250809201608.png|700]]

## skip list

![[Pasted image 20250809202210.png||700]]
插入操作更方便，复杂性低，但引入了冗余的数据副本

## Trie

字典树，与 b+ 相比，trie能更快的判断一个 key 是否存在，并占用更少的空间

## inverted index

倒排索引，在查找具有某个关键词的**全文索引**时使用

从 value 出发，倒序地建立索引：
- 执行 insert 行为时，扫描全部的词汇，将该 value 对应的 **指针** 插入相应字典

## vector index

与 inverted index相比，倒排索引的结果是精确的，而 vector index 会从更高的层次理解语义，进行查找

使用 vector 查找相近的结果，不能保证完全精确

# Lecture 10 并发 Index

> Lock VS. Latch
> ![[Pasted image 20250809215728.png|600]]
> ![[Pasted image 20250809215917.png|600]]

在 B+ Tree 中，如果一个节点不会引发合并，不会影响祖先节点，那么就可以释放上层锁
向下获取锁的过程采用 crab 规则

在 Project2 中我使用的是 悲观锁，对所有操作几乎都是写锁
然而实际情景中，root节点很少会变动，不需要对 root 加写锁，导致低并发
而*乐观锁*机制是：
- 从 root 一路向下，找到 leaf 节点，一路上只加读锁
-  只对 leaf 加写锁
- 如果需要合并，影响上层，就全部推翻，重新从 root 开始获得写锁

**Latch 是针对于数据结构的，而 Lock 是针对逻辑事务的**

# Lecture 11 sort
## topN 堆排序
直接在内存中维护堆即可
## 外部归并排序
在 buffer 中进行 merge 
优化：
1. 双缓存：一个用于计算，一个用于提前获取下批数据，实现一定的 IO 并行
2. 比较函数：对复杂类型，采用编码后的内联排序指令，减少函数调用，也可以采用前缀比较
3. 索引：采用现成的索引（比如 B+ 树）

## 聚合
一般采用 Hash 做法，聚集 key 相同的数据
步骤：
1. 过滤 key
2. 将相同 key 集中映射到一块分区
3. 重新遍历分区，进行二次映射，计算结果

![[Pasted image 20250809224148.png|600]]
![[Pasted image 20250809224245.png|600]]

# Lecture 12 Join
![[Pasted image 20250809225456.png|600]]

# Lecture 13 查询模型

迭代器模型、物化模型、向量模型
惰性求值，即时编、Index Scan

# Lecture 14 查询并发

水平并发、垂直并发
Worker 线程，分区提高 IO 并行

# Lecture 15 查询计划与优化

谓词下推
Join 优化：动态规划、剪枝搜索
代价估算：统计数据、抽样
![[Pasted image 20250810130835.png|600]]

# Lecture 16 并发控制
ACID
原子性：logging、影子分页
可串行化

# Lecture 17 两阶段锁
读写锁、意向锁、两阶段
死锁处理：回滚、checkpoint
2PL是一种悲观处理

# Lecture 18 乐观并发控制
乐观：基于时间戳，先运行，真实写入前再验证是否冲突
幻读问题：
1. 加大锁
2. 扫描检查
3. 谓词锁
4. 索引锁（最常用）
![[Pasted image 20250814211702.png|600]]

# Lecture 19 MVCC 多版本控制协议
基于时间戳快照，读写冲突减少，不存在物理上的数据覆盖
![[Pasted image 20250814214651.png|600]]
快照隔离不是可序列化的，应该保护所有数据