#reading 
#计算机网络 
# Chapter 3 运输层
#####  Intro
- [[TCP]] 和 [[UDP]] 协议
- 运输层 与 网络层 的关系（UDP）
- 如何实现可靠通信（TCP）
- 应对拥塞控制
## 3.1 概述和运输层服务
运输层实现应用间的[[逻辑通信]]
运输层协议在端系统中实现
将应用层发送的报文分组，称为**运输层报文段（segment）**
### 3.1.1 运输层和网络层的关系
网络层提供端系统（主机）之间的通讯
而运输层则提供不同主机上 **应用进程** 之间的逻辑通信，调用了网络层的接口

网络层所能提供的服务范围，一定程度上会限制运输层的服务质量，但不完全决定

### 3.1.2 因特网运输层概述
本书将 UDP 和 TCP 的 *运输层分组* 统称为 *报文段（segment）*

网络层协议为 *IP协议*，它是**不可靠的**
*每台主机有一个 IP 地址*

运输层的责任是：将 IP 协议提供的端到端服务，扩展到进程间服务，这被称为运输层的*多路复用*与*多路分解*

UDP：不可靠
TCP：可靠，具有拥塞控制

## 3.2 [[多路复用与多路分解]]

运输层实现 主机间交付 扩展到 进程间交付

运输层不直接把 segment 给到相应进程，而是先定向至 socket

识别 segment 字段，决定送到哪个 socket 的工作称为 多路分解
从 socket 中收集报文，封装首部字段为 segment，交给网络层的工作称为 多路复用

多路复用的要求：
1. socket 标识符唯一
2. segment 首部必须指明要定向至的 socket
	- 这样的字段是 *源端口号字段* 和 *目的端口号字段*
	- 端口号的范围是 `0~65535`, 周知端口号则为`0~1023`

### 无连接的多路复用和多路分解（UDP）

工作过程：
1. client 分配一个 UDP socket 与 端口号，将 源 IP 与 目的 IP 封装到 segment 
2. 网络层将 segment 从 client 传输至 目的 IP 的 server
3. server 分解 segment ，送至对应的 目的端口号
4. server 服务结束后，利用收到的源 IP 和 端口号，作为新的目的，将服务结果发送回 client

UDP socket 由二元组 `(目的 IP, 目的 端口号)`标识
只要目的地相同，就可以分配给同一个 socket

### 面向连接的多路复用和多路分解（TCP）

TCP socket 由四元组 `(源 IP, 源 端口号, 目的 IP, 目的 端口号)`标识
如果源不同，就必须分配给不同的 socket，**除非是首次连接请求**

工作过程：
1. server 的 welcome socket 等待 client 的连接请求
2. 接到请求后，server 创建一个新的 socket，并告知 client 可以经过该 socket 进行通信
3. client 收到允许连接的信号后，与 server 给定的 socket 建立连接，开始通信
4. 后续与 UDP 类似

### Web 服务器与 TCP

Web 服务器的周知端口号为 *Port 80*

socket 与 进程 **并非**是 一一对应 的关系

在现代 Web 服务器中，通常只有一个进程，为每个 client 连接创建一个连接到新 socket 的 新线程

此时 socket 与 进程 是 **多对一** 的关系


## 3.3 无连接运输：[[UDP]]

即便是最简化的运输层协议，也**不能什么都不做**！
最低限度是提供一种**复用/分解**服务

UDP 大致就是这样一种最低限度的服务
使用 UDP 几乎就是和 IP 协议直接交互

使用 UDP 而不使用 TCP 的理由：
1. 前提：容忍 UDP 的不可靠性
2. UDP 没有拥塞控制，说发就发
3. UDP 不需要麻烦的握手协议
4. UDP 不用维护连接状态信息
5. UDP 的 segment 首部信息更短

UDP 更能承受高压的传输需求

使用 UDP 的例子：DNS 服务，多媒体服务

UDP 的不可靠性，可以通过软件来实现可靠化

UDP 缺乏拥塞控制，这在一些实际情景中是致命的

### 3.3.1 UDP 报文段结构
- 源端口号
- 目的端口号
- 长度
- 检验和
- 应用数据（报文）

### 3.3.2 UDP 检验和

检验和用于提供差错检测功能，16bit字的和的反码

底层的协议不一定实现检错功能，所以在运输层实现这样的功能是很有必要的，体现了*端到端原则*

作为保险措施，UDP **无法**修正错误，只能给出警告

## 3.4 可靠数据传输原理

[[rdt]]: reliable date transfer

TCP 为上层提供可靠的信道抽象，以下层的不可靠信道为接口，开发协议，实现可靠数据传输

本节仅考虑*单向数据传输*，假设信息不会乱序到达

### 3.4.1 构造可靠数据传输协议

现在我们从理想情况出发，一步步放宽假设，逐步构建协议

#### 1. 最理想：信道完全可靠【rdt1.0】

我们以有限状态机（FSM，Finite-State Machine）来描述协议

记发送端为 sh（send host），接收端为 rh（recieve host）

sh 和 rh 的 FSM 只有一个状态，永远循环

由于信道完全可靠，所以机械地处理信息就可以

#### 2. 处理比特差错【rdt2.0】

可能发送 0，收到 1

这种情况下，需要 sh 进行数据重传

- sh 如何得知何时重传？
	- rh 收到分组后，应给予确认回复
		- 若 sh 收到肯定确认，不再重传
		- sh 收到否定确认，重传

基于这种重传机制的 RDT 称为 *自动重传请求协议（ARQ，Automatic Repeat reQuest)*

ARQ 应实现的服务：
1. 差错检测
2. 接收方反馈
	-  **ACK** 标记 肯定确认 acknowledge
	-  **NAK** 标记 否定确认
3. 发送方重传

sh 的 FSM 有两个状态：
1. 等待上层的指示
	- 发送信息，变为状态 `2`
2. 已发送信息，等待 rh 的确认反馈
	- `ACK` ：结束等待，回到状态 `1`
	- `NAK` ：重传分组，等待 rh 的新反馈，留在状态 `2`

sh 这种一直等待 rh 反馈的行为，被称为*停等协议*

rh FSM 状态：
1. 等待下层的信息
	- 接收信息
	- 差错检测
		- 无误，发送 `ACK` 信号
		- 有误，发送 `NAK` 信号，要求重传
	- 留在状态 `1`

rdt2.0 存在一个致命的缺陷：发回的**确认信号**也可能出错

考虑如何处理 受损的 ACK 与 NAK：
1. sh 无法识别 rh 的回复，因此询问 rh ，要求重传她的回复，但 sh 的要求回复又可能出错，导致 rh 开始迷惑，这种情况陷入一种纠缠不清的境地，**不可行**
2. rh 在回复时，增加**足够多的校验**信息，使得 sh 不仅能检测差错，而且能够自助地修正差错，对于不丢包的信道可以解决问题
3. sh 不再费心思考虑 rh 的真实想法，直接从头来过，**重传**整个数据分组
	- 产生冗余分组：rh 不明白，明明已经给出了 ACK，却收到了与上次一模一样的包，这个包，到底是 rh 自己想要的新分组，还是 sh 没有听到 ACK，自作主张发送的重传分组，双方缺乏交流，导致歧义
	- 解决歧义问题的方式很简单：
		- 在首段添加 segment 的**序号**即可
		- 有了双方的共同约定，包的语义不会被混淆

要分辨是重传包还是新包，只需要一个 bit 位即可

如果 sh 发送了一个 0 包，rh 却表示收到了一个 1 包，给出 ACK 确认，那么就能判断发生了反馈失传

rdt2.1 和 rdt2.2 就采用这种设计，FSM 的状态数也相应地翻倍，FSM 状态增加了一维，表示当前期望得到 0 包还是 1 包

不再给出 FSM 的详细描述

记期望包号为 sn（segment number）

假设 rh 的回复要么是 ACK 或 NAK，要么是含糊不清的

对 rdt2.1
- 该协议收到失序分组时发送 `ACK`，错误分组发送 `NAK`
- *发送有误分组的 `ACK`，与发送 `NAK` 等效*
- sh 收到的 rh 回答 A 含糊不清，选择重传 0 包，下次回答有这些情况
	1. sh 收到 rh 回答 `ACK 0` 、`NAK 0`
		- 说明 rh 之前的回答 A 是要求重传 0 包 `NAK 0`
		- 正常运行
	2. sh 收到 rh 回答 `ACK 1`
		- 说明 rh 之前的回答 A 是成功收到 0 包 `ACK 0`
		- sh 明白自己传了一个冗余包，补救错误
		- rh 也知道 sh 传错了包，对失序包回答 `ACK`，但知道自己下一个还是想要一个 1 包
	3. sh 收到 rh 回答 `NAK 1`
		- sh 多传了一个错包
		- 同上，sh 和 rh 都知道该怎么做


rdt2.2 与 rdt2.1 的设计大致相同，只不过舍弃了 `NAK` 信号，用等效的 `ACK bit` 信号替代 `NAK`

FSM rdt2.2 的特性可以概括为：
1. rh 发了 `ACK 0`，下一个就要传 1 包
2. rh 发了 `ACK 1`，下一个就要传 0 包
3. rh 收不到 1 包，就一直发 `ACK 0`
4. rh 收不到 0 包，就一直发 `ACK 1`
5. sh 和 rh 一旦收到错包，就一直在原状态循环等待

如果 rh 想要 1 包，sh 却一直发 0 包呢？
- 必须证明这种情况不可能存在：
	- *如果 rh 想要 1 包，那么它一定会回答 `ACK 0`*
	- sh 收到 `ACK 0` **认为 rh 收到 0 包**了，于是准备发 1 包
	- 而 rh 只是**欺骗 sh 收到 0 包**
	- 实际 sh 发送的 0 包早就被 rh **丢弃**
	- 因此不存在冗余分组的问题
- 所以 sh 不可能一直发 0 包，证毕

至此完成 rdt2.2 的设计与检验

#### 3. 处理丢包信道【rdt3.0】

如何检测丢包
- 让发送方检测：
	- 如果一段时间后，始终收不到对应分组的 ACK 回应，认为丢包
- 然后发送方采用它的万能灵药：重传
- 实现基于时间的重传机制，发送方需要做到：
	1. 每次发送分组后，启动一个计时器
	2. 响应计时器中断
	3. 终止计时器

rdt3.0 的 FSM 设计：
- 状态同 rdt2.2
- 当且仅当发生超时 `timeout` 时才重传包
- sh 收到想要的 `ACK` 回复时，就终止计时器，转移状态
- sh 收到不想要的 `ACK` 时，什么也不做，把重传任务交给 `timeout`

分组序号在 0/1 间交替，rdt3.0 被称为 *比特交替协议*

### 3.4.2 流水线[[可靠数据传输协议]]

rdt3.0 的性能有限：它是一个*停等协议*

一个简单的解决方式是：允许发送方发送多个分组而无须等待确认
这种技术被称为*流水线*

流水线带来的技术要求：
1. 必须增加序号范围
2. sh 与 rh 不得不缓存短时间内到达的多个分组
3. 差错处理
	- 回退 N 步（Go-back-N，GBN）
	- 选择重传（Selective Repeat，SR）

### 3.4.3 回退 N 步

GBN 协议，限制流水线中未确认的分组不能超过 N 个，因此 GBN 也被称为 *滑动窗口协议*

GBN 也可用 FSM 描述

下面给出 GBN sh 对事件的响应策略：
1. 上层的调用
	- 首先检查窗口是否已满
		- 若满，返回，指示上层稍后再试
		- 不满，发送分组并更新变量
	- 也可限制上层仅在窗口不满时，才可发送信息
2. 收到一个`ACK`
	- 对序号为 `n` 的分组采取*累计确认*
3. 超时
	- 回退 N 步，重传所有仍未确认的分组

GBN rh：
- 收到序号 `n`，如果有序到达（前一个收到`n-1`），则正常接收
- 否则丢弃该包，回答最后一个按序到达的包的 `ACK`
- 只要失序，就丢弃
	- 这种策略浪费了正确发送的包，是有理由的
	- 数据必须按序交付，保留失序包的代价可能更大
	- 优点是
		- 缓存简单，维护信息少

GBN 的工作过程中，每收到一个连续的`ACK`便向前滑动窗口，发送新分组

GBN 的这种实现方式被叫做*基于事件编程*

### 3.4.4 选择重传

尽管 GBN 协议充分利用了空余信道，但由于会丢弃失序分组，可能会造成大量的不必要重传

*选择重传协议（SR）* 让发送方仅重传那些它怀疑再接收方出错的分组，避免不必要的重传

SR sh 会缓存收到的 `ACK` 信号 *（不论是否有序）*
SR rh 会缓存收到的无序分组，直到有序分组到达才交付给上层

SR 的事件与 GBN 相似，但具备了缓存数据和 ACK 信号的功能
- 最大的区别是：
	- SR rh 在收到窗口内的无序分组后，不会选择丢弃，而是发送对应的 `ACK` 信号，并缓存到本地，等待有序分组到达再交付

当 多个 `ACK` 回答丢包时，sh 会尝试重传所有分组，
但是 rh 已经在缓存里收到这些分组，并且**已经移动了窗口**

此时产生 sh 与 rh 间的窗口**不同步**，这是致命的

为解决同步问题，在 rh 端应当处理这种情况：
- 当 sh 发送了一个早已滑过的上一窗口的分组时，**rh 仍要回答 `ACK` 信号**，以使得 sh 滑动本地的窗口，完成同步

此外还有一个限制：**窗口长度必须不大于序号空间大小的一半**

由于序号是模运算，当 sh 窗口 和 rh 窗口 中均包含同一个序号时，若窗口过大，很可能出现歧义：
- sh 中 包含 `x + N` 包，rh 中 包含 `x + N` 包，sh 发送新包 `x + N`，序号为 `x`
- sh 中 包含 `x` 包，rh 中 包含 `x + N` 包，`x` 包已经收到，但是 `ACK x` 信号丢包，此时 sh 认为 rh 没有收到 `x` 包，发送重传包 `x`，序号也为 `x`
- 此时 rh 无法分布 sh 是重传包还是新包

因此 sh 和 rh 的窗口大小之和，绝对不能超过序号空间大小，否则对于模`N`运算会有歧义

---

最后，我们放松对于分组到达顺序的假设，认为分组可能以乱序到达

这种情况下，可能一个无用的重传包可能会最后到达，导致和新包的混淆，此时它并不在滑动窗口中，我们怎么消灭它是一个旧包的可能性呢？

实际采用的方法是，假定一个 `x` 包，在网络中的存活时间有一个上限，在全部旧包死亡前，不冒任何使用 `x` 序号的风险

即如果不能确保旧包全部死亡，就不接受任何新包的操作

在 TCP 中认为存活寿命为 3 分钟

用到的机制：
1. 检验和
2. 定时器
3. 序号
4. 确认
5. 否定确认
6. 窗口、流水线

## 3.5 面向连接的运输：[[TCP]]

### 3.5.1 TCP 连接

TCP 是面向连接的，但不是物理意义上的，而是逻辑连接
TCP 协议只在端系统中运行，中间的网络元素不会位置 TCP 连接状态

点对点、双向、三次握手、数据缓存

TCP 的组成包括：
1. 发送缓存 和 接收缓存
2. 变量
	- MSS ：最大报文段长度，典型值为 1460 Byte
3. 与进程连接的套接字

### 3.5.2 TCP 报文段结构

1. 源端口号、目的端口号、校验和
2. 序号字段、确认号字段
	- 用于可靠数据传输
3. 接收窗口字段
	- 用于流量控制
4. 首部长度字段
5. 选项字段
6. 标志字段
	- ACK
	- RST、SYN、FIN
	- CWR、ECE
	- PSH
	- URG

#### 序号和确认号

TCP 给每个字节编号，并认为某个报文段的序号就是其首字节的编号
*TCP 把数据看作 无结构的、有序的 字节流*

确认号字段，填写 rh 希望从 sh 得到的下一个包的序号

对于失序包的处理方式，由 TCP 的编程人员自行决定

#### Telent：序号和确认号的一个学习案例

telent 无加密、回显命令

### 3.5.3 往返时间的估计与超时

TCP 采用超时重传机制处理丢包，带来以下问题：
1. 超时间隔应设置为多大？
2. 起初如何估计往返时间 RTT ？
3. 是否要为所有报文设定计时器？

#### 估计往返时间

每隔一段时间，测量一次样本 RTT（SampleRTT），用样本估计 RTT

由于 SampleRTT 具有波动性，因此采用**指数加权移动平均（EWMA）**

TCP 维护一个 RTT 均值（EstimatedRTT）

每次测量，用
$$
	EstimatedRTT = (1 - \alpha) \times Estimated RTT + \alpha \times SampleRTT
$$
更新 RTT，推荐 $\alpha = 0.125$


RTT 偏差 DevRTT 用下式计算：

$$
DevRTT = (1 - \beta) \times DevRTT + \beta \times \lvert SampleRTT - EstimatedRTT \rvert
$$

推荐 $\beta = 0.25$

#### 设置和管理重传超时间隔

超时间隔设为：
$$
TimeoutInterval = EstimatedRTT + 4 \times DevRTT
$$
推荐初始超时间隔为 $1s$
超时后 TI 将翻倍，在 ERTT更新时重置

### 3.5.4 可靠数据传输

TCP 仅使用单一计时器，以节省开销

与重传有关的三个事件：
1. 上层调用接口
	- 生成 TCP segment
	- 启动定时器
	- 发送 segment
2. 计时器超时
	- 重传最小序号但未应答的segment
	- 启动定时器
3. 收到 rh 的 ACK 信号
	- 累积确认 segment
	- 若仍有未确认的 segment，启动计时器

#### 一些有趣的情况

1. 确认丢失，可能会导致超时重传
2. 连续发送两个报文
	- 确认 1 和 2 都超时到达，导致 1 包重传，重置计时器
	- 第二个超时间隔内，确认 2 到达，sh 不会重传 2 包
3. 连续发送两个报文
	- 确认 1 丢失，但确认 2 在超时前到达
	- 由于累积确认，sh 收到确认 2，了解 rh 成功接收 1 包和 2 包
	- sh 不会重传任何包

#### 超时间隔加倍

每次重传，sh 将 TimeoutInterval 翻倍，成指数型增长

理由是：超时可能是由网络拥塞造成，过多的重传反而会加重拥塞，需要限制重传次数

#### 快速重传

当超时间隔过长时，一个 1ms 前早就丢失的包，却要继续等待 1000ms 的超时周期结束时才能重传

针对这种情况，采用**冗余 ACK** 检测丢包

当 rh 收到一个失序包时，推测 sh 有丢包，此时 rh 发送一个冗余 ACK

失序 ACK 也可能是数据在网络中自然更改了顺序，所有一个冗余 ACK 不足以让 sh 确信有丢包

故 sh 在收到 3 个相同的 冗余 ACK 后，才断言出现丢包，执行**快速重传**，此时不需要等待计时器超时

#### 是回退 N 步还是选择重传

TCP 是一个 GBN 协议，还是一个 SR 协议？

一方面，TCP 采用累计确认，只维护 rh 接受的边界序号与下一个要发送的序号，具有 GBN 风格

另一方面，有许多 TCP 采用 rh 缓存失序分组

当数据全部正确按序到达，仅仅丢失了 rh 对第一个包 0 包的 `ACK` 信号时
- GBN sh 采用累积确认，会忽略其余所有成功发送的 `ACK` 信号，一次超时就重传所有 N 包
- 而 TCP sh **一次只重传一个包**，在重传完 0 包后，rh 会反馈已经收到了所有 N 个包，因此 sh 只会重传 0 包
- 对于 TCP sh，若超时前，其余 `ACK` 信号先一步到达，sh 甚至不会重传 0 包，而 GBN 的滑动窗口策略，导致其只会忽略这些信号

一种对 TCP 的建议是，采用**选择确认**
选择性地 ACK 一部分失序包的序号，在重传时可以跳过这些包，这样就具备了一些 SR 协议的属性

因此 TCP 协议可以被认为是二者的混合体 

### 3.5.5 流量控制

由于 sh 与 rh 中缓存的存在，我们需要考虑缓存溢出的问题，进而设计**流量控制服务**

*流量控制实际是一个速度匹配服务*

当 网络层 出现拥塞时，sh 会一直延长超时间隔，这种情况下的控制被称为**拥塞控制**

这两种控制是针对不同原因采取的控制

我们在 sh 和 rh 两端维护一个接收窗口相关的变量即可，记录
1. 缓存总量
2. rh 收到的字节
3. rh 交给上层的字节数
4. 剩余缓存大小
并封装在 segment 首部进行传递

sh 在运行过程中始终保持剩余缓存非负，借此实现流量控制

当 rh 缓存已满后，sh 不会再向 rh 主动发送信息，这导致即使 rh 清出了缓存空间，sh 也无从得知！

为处理这种情况，我们强制 sh 在缓存已满时，不间断地向 rh 发送只有一个字节的 segment

这样 rh 就可以在对 sh ”骚扰报文“ 的回复报文中，夹带关于接收窗口的信息，使得 sh 得知何时可以重新传送数据

UDP 不提供流量控制

### 3.5.6 TCP 连接管理

方便叙述，下面 client、server 依旧沿用 sh、rh 的表述

TCP 连接建立过程：
1. sh 向 rh 发送 TCP `SYN` 报文，并随机化 sh 初始序号（防攻击）
2. rh 收到 `SYN` 报文，为该 TCP 连接分配缓存和变量，随机化 rh 初始信号，回复一条 TCP `SYNACK` 报文
	- 此时双方完成空间分配与序号交换
3. sh 收到 `SYNACK` 报文，为连接分配缓存与变量，向 rh 发送确认报文，该报文中 SYN bit 置为 0
	- 三次握手结束，第三次可以携带正常数据

三次握手：
1. 请求
2. 确认请求
3. 确认 请求得到确认

连接关闭：
1. sh 发送 `FIN` 报文，表示 sh 将关闭，等待 rh 的 `FIN`
2. rh 回复 `ACK` 报文
3. rh 发送 `FIN` 报文，表示 rh 将关闭
4. sh 回复 `ACK` 报文，定时等待 rh 的响应
	- 若 rh 没收到 `ACK`，则会进行 `FIN` 重传
	- 一段时间后，sh 没收到 rh 的重传，认为 `ACK` 已被接收
5. sh 关闭，rh 收到 `ACK` 后关闭

TCP 连接过程可用 FSM 描述
这里只给出原书的状态名，转移可由上面推理出

sh 状态名
1. CLOSED
2. SYN_SENT
3. ESTABLISHED
4. FIN_WAIT_1
5. FIN_WAIT_2
6. TIME_WAIT

rh 状态名
1. CLOSED
2. LISTEN
3. STN_RCVD
4. ESTABISHED
5. CLOSE_WAIT
6. LAST_ACK

*SYN洪泛攻击*
- 大量的 sh 发送 SYN 信息，却不进行第三次握手，使得 rh 端分配大量无用连接资源
- 第二次 SYNACK 握手时，rh 保有 sh 的 SYN 信息，因此可以分配资源，而第三次握手是一次 ACK 信息，怎么分配资源呢？
- 我们采用 *SYN cookie* 技术，将第三次 ACK 与 第一次 SYN 建立映射，从而具备**只为给出了第三次握手的合法用户**分配资源的能力

上面假设 sh 与 rh 都准备好通信，监听端口正常

如果 sh 请求的 socket，rh 并不提供，此时 rh 会回复 `RST` 特殊重置 segment，告知 sh 该 socket 并不合法，不要再发送了

nmap 端口扫描工具：
- 向目的端口发送 `SYN` 报文
1. 若收到 `SYNACK` ，意味着目的端口对外开放
2. 若收到 `RST`，意味着不开放，并且我们的报文可以直接抵达主机
3. 若什么都没收到，我们的报文可能被防火墙所阻挡

## 3.6 [[拥塞控制原理]]

### 3.6.1 拥塞原因与代价

#### 情况 1：两个发送方和一台具有无穷大缓存的路由器

吞吐量的上限由链路带宽决定，传输速率越接近吞吐量上限，时延就越趋近于无穷大

*当分组的到达速率接近链路容量时，分组经历巨大的排队时延*

#### 情况 2：两个发送方和一台具有有限缓存的路由器


缓存有限，难免会发送丢包
*发送方必须执行重传以补偿因为缓存溢出而丢弃的分组*


排队时延过长，使得 sh 错误地认为已经丢包，发送不必要的重传
*发送方再遇到大时延时所进行的不必要重传会引起路由器利用其链路带宽来转发不必要的分组副本*


#### 情况 3：4个发送方和具有有限缓存的多台路由器及多跳路径

多跳路径下，先来的包可能会被后来的包排挤出缓存
*当一个分组沿一条路径被丢弃时，每个上游路由器用于转发该分组到丢弃该分组而使用的传输容量最终被浪费掉了*

### 3.6.2 拥塞控制方法

1. 端到端拥塞控制
2. 网络辅助的拥塞控制
	- 路由器显式地向上层提供关于拥塞的信息

## 3.7 TCP 拥塞控制

### 3.7.1 经典的 TCP 拥塞控制

TCP 根据感知到的拥塞程度，来控制发送流量的速率
1. 如何控制流量？
	- 跟踪一个额外变量：*拥塞窗口* cwnd
	- 修改 cwnd，与 *接收窗口* rwnd 共同作用即可
2. 如何感知拥塞？
	- 指示丢包：超时、或连续三个冗余 ACK
3. 如何确定怎么改变流量速率？
	- 没有拥塞时，通过测量 ACK 的时间，来猜测带宽占用情况，缓慢或迅速地改变速率
	- 确认丢包时，减速
	- 收到 ACK 时，增速
	- 不定期地探测带宽：
		- 先增大速率，试探带宽拥塞的底线
		- 随后逐渐减小速率，直至满意

**TCP 拥塞控制算法**
1. 慢启动
2. 拥塞避免
3. 快速恢复
#### 慢启动
以 1 个 MSS 作为 cwnd 的初始值，该初始值较低

下面省略单位 MSS

每收到一个成功的 ACK，cwnd 就增长 1 
此后 cwnd 成指数增长

何时结束这种增长？
- 当检测到超时，就重置 cwnd 至 1 ，同时设置 ssthresh（慢启动阈值）为 cwnd/2
- 当 cwnd 达到 ssthresh 时，结束慢启动，并转移到到拥塞避免模式
- 检测到 3 个冗余 ACK 时，将 cwnd 重置为 ssthresh + 3 执行快速重传并进入快速恢复状态

*大步增长*

#### 拥塞避免

此时每个 RTT 增长 1

超时就重置回慢启动
三个冗余 ACK 就快速恢复

*小步增长*
#### 快速恢复（非必须但推荐）

每收到一个冗余 ACK，就增长 1

超时就重置进入慢启动
收到新 ACK 就返回拥塞避免模式

*抵消丢包带来的后续大量冗余 ACK 的影响*

#### TCP拥塞控制：回顾

拥塞控制：每个 RTT 内增加 1，三连冗余时减半
因此 TCP 拥塞控制被称为**加性增、乘性减（AIMD）** 方式

#### TCP CUBIC

TCP Reno 每次都把 cwnd 减半再线性试探，速度慢

认为 AIMD 方式过于谨慎，我们完全可以先快速逼近拥塞上限，再开始线性探测

TCP CUBIC 就以此想法为核心，仍保留慢启动和快速恢复
- 预测达到上界的时间点 K
- 以 ${\lvert t - K\rvert}^3$ 为函数来增加 cwnd
	- 当接近界限时，增长速度开始放慢
	- 但当越过界限时，增长速度则会迅速变大，有利于找到新的临界点，避免在低水平缓慢线性加试探

*Linux 使用 TCP CUBIC*
#### 对 TCP 吞吐量的宏观描述

由于 AIMD 方式的运行，cwnd 总是在 W/2 和 W 之间反复横跳，易知平均吞吐量为 $\frac{0.75 \times W}{RTT}$

### 3.7.2 网络辅助明确拥塞通告和基于时延的拥塞控制

#### 明确拥塞通告（ECN）

路由器在 IP 报文中设置 ECN bit 以通知拥塞

rh 收到 ECN 通知后，在 TCP ACK 报文中设置 ECN 回显 bit（ECE），通知 sh 发生拥塞

sh 收到 ECE 通知后，进行拥塞控制行为

#### 基于时延的拥塞控制

在丢包之前，主动检测拥塞

sh 测量所有分组在理想状态下（无拥塞、排队短）的 RTT ，认为未拥塞吞吐量为 $cwnd/RTT_{min}$

当测得的实际吞吐量小于这个值时，增速，反之则减速

### 3.7.3 公平性

假设 两个 TCP 连接的 MSS 与 RTT 相同，那么AIMD 控制总会向平等状态收敛

但实际情况中，RTT 总是不相同，导致不平等

#### 公平性和 UDP

UDP 宁可丢包，也从不进行拥塞控制，因此流媒体这样的应用更钟情于 UDP

但也导致 UDP 可能自私地抢占大量带宽

#### 公平性和并行 TCP 连接

一个应用可能同时使用多条 TCP 连接，而另一条仅仅建立一条 TCP 连接，导致资源分配不平衡


## 3.8 运输层功能的演化

TCP 拥有许多不同的变种和版本，这些协议唯一共同的特征是使用 TCP 报文段格式，面对拥塞会公平竞争

### QUIC
快速 UDP 互联网连接

QUIC 是一种新型应用层协议，用于提高安全 HTTP 的运输层服务的性能，使用 UDP 运输层协议

特征：
- 面向连接和安全
- 数据流
- 可靠的、TCP 友好的拥塞控制数传输

传统安全 HTTP 协议栈：
- HTTP/2 + TLS

HTTP/3协议栈：
- HTTP/2（精简） + QUIC = HTTP/3