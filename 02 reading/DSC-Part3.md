# 数据管理实现技术

## Ch10 存储管理
### 物理存储设备（跳过）
### 文件组织

#### 块使用

*数据是如何在块中存放的*

- 空闲空间用链表组织
- 定长数据不会跨 block 存储
- block head 记录文件信息
- 位图表示数据是否为空
- 实际上记录从 block 末尾向低位存储，中间部分留作自由空间
- 插入变长记录时，可分配空闲空间
- record 可以为间接引用指针，防止内存碎片
- big file 采用指针，或者外部文件系统来存储

---
#### 文件使用

*记录（元组）是如何在文件中组织的*

1. 堆组织：无序
2. 顺序组织
3. 多表聚簇组织：不同记录集中在同一文件
4. B+树组织：基于索引
5. Hash组织

**堆组织**：
- 依靠 多级bitmap 分配空闲块

**顺序组织**：
- 按关键字排序，插入成本高
- 如果按链表存储，则失去空间局部性

**多表聚簇组织**：
- 将多个关系存储在同一个 block
- 读块时可以一并存入缓存，减少磁盘交互

> *Table Partitioning*
> 可以按某个特定属性值为依据，将一个大表分成若干小表，分别存储在不同的块，这样调用 `WHERE x=100` 这样的查询时，可以直接找出对应的块，减少磁盘交互

---
#### 字典与缓存

数据字典用于存储 **metadata** 

**缓存区管理器**：
- 使用 **LRU 策略**
- 缓存区被认为是临界区域，需要进行**读写保护**
- 并发情景下，需要对块执行 `pin` **钉住**操作（防止移出）
- 进程会申请**共享锁**（只读）、**排他锁**（读写）
- 可以**提前写回**缓存块，或**强制写出**
- 替换策略：LRU、MRU、立即丢弃
- 利用 **日志系统** 完成崩溃恢复

---
## Ch11 索引

两种索引：**顺序**与**递归**
评价标准：
1. 访问类型
2. 访问时间
3. 插入时间
4. 删除时间
5. 空间开销

### 顺序索引

一个文件有其对应的 **[[搜索码]]** ，用于排序后顺序查找
不同的搜索码，可以对应不同的查找规则

分为 [[聚集索引]] 和 [[辅助索引]]

两类顺序索引：
1. [[稠密索引]]
2. [[稀疏索引]]：分块，只索引块头

多级索引

---
### B+树索引

**平衡树**结构：
1. 叶节点存储**搜索值与指针**
2. 非叶节点存储多级索引

B+树一般胖而矮，因为节点空间较大，与磁盘块规模相当

$N$ 通常为 $50$ 或 $100$

B+树的性能优势体现在 **磁盘读取次数** 上，必须结合硬件访存速度来设计数据结构

查询是 $O(log N)$ 级别的

节点会进行分裂与合并

B+树保证所有叶子节点都在同一层，而更新只在叶子层发生，因此整个树的层次更新是同步的

如果分裂合并影响父节点，就一直向上递归传递影响
若到达根节点，根节点要么分裂出新一层，要么合并一层

---

### 散列索引

采用哈希函数，直接寻找存有记录的 bucket

---

### 多码访问

实现方式：
1. 采用多个属性组成的 **复合搜索码**，排序情境下表现差
2. 对多个 **单值搜索码** 取交集，可能查询大量无用索引
3. **覆盖索引**：在索引节点内部，存储一些额外信息作为缓存，使得不需要访问记录的实际 block

---
### 位图索引

适用于属性值域较小的情景

利用位运算 加速 集合运算

先通过位图运算，选出候选集合
- 如果候选记录较多，那么全部扫描的策略也可以接受
- 否则就从候选记录中找，因为已经通过位图筛选掉了大量无关记录

---
## Ch12 查询处理和查询优化

### 概述

查询处理的步骤：
1. 语法分析与翻译
2. 优化
3. 执行

查询代价估计：
1. 传输块数
2. 随机 IO 访问数
3. 缓存影响

---
### 关系代数运算的执行

#### select 运算

- 线性查找、聚集索引、辅助索引
- 等值比较、比较

线性查找是最差选择，辅助索引会带来大量随机 IO 操作

PostgreSQL 使用了**位图索引扫描**的算法，提前过滤不可能选择的 tuple

---
选择谓词：**合取、析取、否定**

合取选择的三个做法：
1. 使用一个索引筛选，随后线性扫描全部的
2. 使用组合索引筛选
3. 先通过索引内部存储的标识信息筛选指针，取交集，排序，再依次查询指针对应的 block

---
数据库情景下，内存大小可能远远小于文件大小，此时需要研究外排序算法

**外排序-归并**

---
#### join 运算

一种简单做法是**嵌套循环**，线性扫描，枚举笛卡尔积的每一项，筛选<br>
考虑空间局部性，内层循环最好能全部装入内存

优化做法是**两两枚举 block**，再检测块连接的每一项，利用空间局部性

优化细节：
1. 可以前后交替遍历，一次正着，一次倒着遍历，充分利用缓存区
2. 可以将内存大小作为两两枚举的对象

**索引嵌套-循环连接**：如果内层循环有索引，就不需要再一一枚举元组，直接访问对应的索引即可

**归并连接**：对查询属性排序后，采用双指针合并

**散列连接**：对两个关系都构建哈希表，分区，将元组划分到不同的哈希索引内，随后只检查桶内部的笛卡尔积即可

**混合散列连接**：只对较小的关系构建哈希表，对大关系则采用循环扫描，探查哈希表的方式进行匹配

---
#### 其他运算

**去重**：排序或散列实现
**投影**：对tuple投影，然后去重
**集合运算**：
- 排序，去重，双指针扫描
- 散列索引，最后将哈希桶合并
**外连接**
**聚集**：与去重类似

---
### 表达式执行

**物化**：将中间结构作为 **临时关系** 储存
**流水线**：
- 操作完成后，不会将临时结果写入到磁盘保存，再从磁盘读回使用，而是直接连接到下一条查询命令，类似于 pipe
- **生产者驱动**或**需求驱动**

---
### 查询优化

优化器步骤：
1. 生成等价表达式
2. 为表达式做注释
3. 估计执行代价，择优

等价表达式的枚举：
- 不同的枚举结果之间，可以共用同一个子表达式
- 枚举之前先估计执行代价，过高就丢弃

---
枚举完成后，需要估计每个查询表达式的执行代价

数据库系统目录存储了关系对象的统计信息：
1. tuple 数
2. tuple 块数
3. tuple 字节数
4. 一个块里的 tuple 数
5. $\Pi_A(r)$ 的规模 

不可能时刻维护该信息，只有处在低负载状态时才维护
因此该信息不精确，只是对执行代价的粗略估计

---
估计完成后，从中选择一个较优的方案

join 满足结合律和交换律，可以自由修改连接次序
采用 **动态规划** 来计算最优次序

而同一个查询命令，也有不同的物理实现方式
这种情境下，依次枚举，采用等价替换物理规则，再估计执行成本
需要剪枝和记忆化优化

启发式优化：
1. 尽早执行 select、投影
2. 搜索到能接受的方案就直接终止
3. 将同一个反复查询的最优方案存入缓存

嵌套子查询可能被当作是函数，被反复执行，最好优化为连接运算

---
## Ch13 事务管理
---
事务需要维护 **[[ACID]]** 特性

### 原子性与持久性

使用状态维护

| 状态名  |   含义   |
| :--: | :----: |
|  活跃  |  初始状态  |
| 部分提交 | 命令执行完成 |
|  失效  | 事务执行失败 |
|  中止  |  已被回滚  |
|  提交  |  写入完成  |

向外部写入信息的操作需要谨慎，尽量在 commit 后再写
崩溃恢复时，可能需要补偿操作

---
### 隔离性

并发执行的优点：
1. 提高吞吐量和资源利用率
2. 减少等待时间

但并发运行，会引起临界区冲突问题，需要维护隔离性

通过**调度**实现串行化

对临界区的两个独立的写入操作 认为是冲突的
通过交换命令顺序，产生与原始串行操作等价的调度序列

检查调度是否是可串行化：
1. 检查操作时序依赖（比如在 write(Q) 后的 read(Q))
2. 对依赖建图，进行拓扑排序

实际情境中，会出现撤销事务的情况
需要 **可恢复调度** 和 **无级联调度**
要求 只有在一个事务 `commit` 完成后，才能 `read` 它修改的一个数据

SQL 的隔离性级别：
- 可串行化
- 可重复读：两次读取期间不允许有其他写入
- 已提交读：只读取 `commit` 数据
- 未提交读

并发控制技术：
1. 锁
2. 时间戳
3. 多版本和快照隔离

在检查谓词时，如果此时产生中断，而其他事务插入了一个新元组，会导致 **幻象** 问题，因此会设计 **谓词锁**

---
## Ch14 并发控制与恢复
---
### 锁协议

两种锁：**只读锁**和**读写锁**

两阶段封锁：增长与缩减

封锁检查可由系统自动实现
一个严格的两阶段封锁，应该保证在 commit 前不释放任何锁

锁表负责维护数据上的封锁请求

如果提前定义封锁之间的依赖关系的话，可以通过拓扑排序来进行封锁

---
### 死锁处理

死锁预防：
1. 提前对封锁进行排序
2. 抢占与事务回滚
	- 如果获取锁失败，就直接回滚
	- 通过时间戳大小比较，判断是否要回滚
3. 超时回滚，如果等待时间过长，自动判断为死锁

死锁检测：
- 通过记录 lock 之间的等待关系，建图
- 拓扑排序，如果图内有环，检测到死锁

死锁恢复：
- 选择一个 deadlock 环中的事务，将其回滚
- 决定回滚距离（可以部分回滚）
- 不要多次选取同一个事务，进行回滚（会 starve）

---
### 多粒度

如果对每个数据项都单独加锁，花销太大

因此会将多个数据绑定，共用同一个锁，产生多粒度控制

lock 的覆盖关系形成树型层次结构

叶子节点是 单个数据的 **显式锁**
而非叶子节点是 数据集合的 **隐式锁**

当封锁根节点时，需要判断整个子树中是否有 lock 已被其他事务占用，为此需要检测整个树
因此提出 **意向锁**，当封锁一个节点时，将其所有祖先节点加锁，表示该子树内存在封锁

增删操作时，注意逻辑意义上的锁

---
### 谓词读、幻象

谓词读时，另一个事务可能会修改满足条件的元组，在一个二者并不共享的 tuple 上发生冲突，导致 **幻象**

因此选择在谓词读时，阻止一切与该谓词的 判定条件 有关的修改操作

仅仅封锁 tuple 是不够的，还要封锁用于访问 tuple 的 metadata：
1. 直接封锁该关系对应的 数据对象
2. 封锁整个索引

另一种技术是 **索引封锁协议**：
- 将对应的索引节点加锁
- 插入或更新时，必须获取索引节点的 lock
- 查找索引时，必须获取 全部 索引 **叶节点** 的 lock
- 将幻象冲突，转化为 **具体节点** 上的冲突

也可以为每个执行中的谓词单独加锁，操作时，检查所有的 **谓词锁序列**，判断是否发生谓词冲突
因成本过高，放弃

---
### 时间戳协议

每个事务关联一个唯一的时间戳：
1. 时钟
2. 计数器

通过保证事务严格按照时间戳顺序串行来保证并发

如果一个读写操作不合法，就回滚该事务，重启后赋予一个新时间戳（逻辑上延迟事务）

值得注意的是，时间戳的顺序并不等同于原事务执行的逻辑顺序（存在重启，此时时间戳被重新分配）

通过冲突检测与回滚，整个系统会保证事务严格按照某个确定的调度顺序执行（只不过可能改变时间戳的排序）

Thomas 写规则：忽略过时的 write 操作（不重启）

仅凭时间戳调度，只能满足逻辑上的事务调度，换句话说，就是不会严格按照用户输入的顺序执行事务

为了保证用户交互上的正确性，保证结果上满足物理上的 “先来后到”，需要通过多版本控制、冲突检测来保证事务执行的等效性

该协议容忍局部的差错，只保证最终效果与外部观测结果一致，对于像支付这样严格要求事务顺序的场景，还是要使用 lock

**有效性检查协议**：
1. 读阶段：将操作数据缓存到工作区，进行修改
2. 检查阶段：检查操作是否与其他事务冲突，有就回滚
3. 写阶段：将工作区缓存写入到数据库

**多版本**：
1. 与时间戳或两阶段封锁结合
2. 核心是保存副本，减少 read 操作的限制，减少封锁与冲突

---
### 崩溃恢复

**日志记录**：先记录操作序列，最后一并 commit

出错时，要么 redo 事务，要么 undo 事务

通过严格的两阶段封锁，防止级联撤销

undo 时，同样要记录 redo-only 日志，结束时写 abort 日志，表示该事务被中止，撤销完成

值得注意的是，恢复系统时，扫描日志，同样要执行 abort 的记录（undo 日志也会执行），这点冗余减少了恢复逻辑的复杂度

checkpoint 将缓存区的所有 block **强制写入磁盘**， 表示在此之前的日志已经成功执行，从而释放 log 空间，减少恢复时间

恢复算法，先从检查点重演历史，再倒序扫描，撤销操作

为减少磁盘写入频率，可以对 log 实行 **组提交**

缓存区一般采用日志缓存，将整个 block 写入磁盘，因此 commit 前，必须先将整个日志写入磁盘

永远是先写日志，再写数据

一个 block 可能被多个事务频繁修改，此时不希望该 block 被反复写入到磁盘，这种方式称为 **非抢占式**

由于多个事务可能共用同一个 block，因此当输出一个 block 时，必须先写入该 block 上的全部日志，并在写出期间持有排他锁

缓存区的两种管理方式：
1. 数据库自己保留一块主存用于缓存，与 OS 独立
2. 数据库在 OS 提供的虚拟内存上建立缓存

模糊检查点：
- 允许在先写入 checkpoint 后，全部 block 写入完成前，更新未占用的 block
- checkpoint 结束时更新 last_checkpoint